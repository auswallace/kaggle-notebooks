{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13560539,"sourceType":"datasetVersion","datasetId":8613526}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (./) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-05T00:18:15.406185Z","iopub.execute_input":"2025-11-05T00:18:15.406367Z","iopub.status.idle":"2025-11-05T00:18:17.541779Z","shell.execute_reply.started":"2025-11-05T00:18:15.406351Z","shell.execute_reply":"2025-11-05T00:18:17.540582Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Summary of Findings\n\nAfter exploring this dataset and building predictive models, here are the main takeaways:\n\n**The Steam gaming landscape is dominated by a few massive titles.** Counter-Strike 2 and PUBG absolutely dwarf everything else, averaging over 300K players each. Meanwhile, the median game has only about 10 players - the distribution is extremely skewed.\n\n**Game populations are surprisingly stable.** This was the biggest surprise. Month-to-month, player counts barely change. We found that 87% of next month's player count can be explained just by looking at this month's numbers. Games tend to maintain their playerbase rather than experiencing wild swings.\n\n**Established games are easy to predict, new releases are chaos.** Our models achieved 97%+ accuracy predicting player counts for stable games like CS2, PUBG, and GTA V. But newer titles like HELLDIVERS 2? The model struggled with 57% error because these games don't follow historical patterns yet - they're still in their volatile launch phase.\n\n**A simple rule works surprisingly well.** We compared our Random Forest model against a \"dumb\" baseline that just predicted \"next month will be the same as last month.\" The naive approach got 98% accuracy. Our fancy model? 97%. Turns out the problem is just inherently easy because gaming populations are so sticky.\n\n**Seasonality exists but is minor.** January sees slightly higher player counts (probably holiday gaming and New Year releases), but the seasonal effect is pretty small compared to the game-to-game differences.\n\n**The platform has grown significantly.** From tracking about 1,000 games in 2012 to over 4,000 in 2025, Steam has massively expanded. But interestingly, the number of tracked games peaked around 2018 and has since declined slightly.\n\nOverall, this analysis revealed that Steam's gaming ecosystem is highly predictable for mature titles, with player counts following strong momentum patterns. The real challenge in forecasting comes from new, viral releases that break the mold.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime, timedelta\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ML libraries\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, IsolationForest\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom scipy.cluster.hierarchy import dendrogram, linkage\nfrom scipy import stats\n\nplt.style.use('seaborn-v0_8-whitegrid')\n%matplotlib inline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T00:18:17.543361Z","iopub.execute_input":"2025-11-05T00:18:17.543759Z","iopub.status.idle":"2025-11-05T00:18:20.101832Z","shell.execute_reply.started":"2025-11-05T00:18:17.543738Z","shell.execute_reply":"2025-11-05T00:18:20.100784Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Load and Prepare Data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/steam-monthly-average-players/steamcharts.csv')\n\n# basic prep\ndf['gain'] = pd.to_numeric(df['gain'], errors='coerce')\ndf['date'] = pd.to_datetime(df['month'], format='%b-%y', errors='coerce')\ndf['year'] = df['date'].dt.year\ndf['month_num'] = df['date'].dt.month\n\n# sort by game and date\ndf = df.sort_values(['steam_appid', 'date'])\n\nprint(f\"Loaded {len(df):,} records\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T00:18:32.963675Z","iopub.execute_input":"2025-11-05T00:18:32.963973Z","iopub.status.idle":"2025-11-05T00:18:34.133167Z","shell.execute_reply.started":"2025-11-05T00:18:32.963952Z","shell.execute_reply":"2025-11-05T00:18:34.132258Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 1. Game Lifecycle Clustering\n\nGroup games based on their player count trajectories over time.","metadata":{}},{"cell_type":"markdown","source":"## Feature Engineering for Clustering","metadata":{}},{"cell_type":"code","source":"# calculate trajectory features for each game\ndef calculate_trajectory_features(group):\n    if len(group) < 3:\n        return None\n    \n    features = {\n        'mean_players': group['avg_players'].mean(),\n        'max_players': group['avg_players'].max(),\n        'min_players': group['avg_players'].min(),\n        'std_players': group['avg_players'].std(),\n        'cv': group['avg_players'].std() / (group['avg_players'].mean() + 1),  # coefficient of variation\n        'total_months': len(group),\n        'growth_rate': group['gain_percent'].mean(),\n        'peak_to_mean_ratio': group['avg_players'].max() / (group['avg_players'].mean() + 1),\n        'months_declining': (group['gain'] < 0).sum() / len(group),\n        'final_to_peak_ratio': group['avg_players'].iloc[-1] / (group['avg_players'].max() + 1)\n    }\n    \n    return pd.Series(features)\n\ngame_features = df.groupby('name').apply(calculate_trajectory_features).dropna()\nprint(f\"Created features for {len(game_features)} games\")\ngame_features.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T00:18:53.802666Z","iopub.execute_input":"2025-11-05T00:18:53.802928Z","iopub.status.idle":"2025-11-05T00:18:57.340184Z","shell.execute_reply.started":"2025-11-05T00:18:53.802909Z","shell.execute_reply":"2025-11-05T00:18:57.339489Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# filter out games with very low player counts to focus on meaningful patterns\ngame_features_filtered = game_features[game_features['mean_players'] >= 5].copy()\nprint(f\"Filtered to {len(game_features_filtered)} games with mean >= 5 players\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T00:19:20.014014Z","iopub.execute_input":"2025-11-05T00:19:20.014263Z","iopub.status.idle":"2025-11-05T00:19:20.021461Z","shell.execute_reply.started":"2025-11-05T00:19:20.014246Z","shell.execute_reply":"2025-11-05T00:19:20.020476Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Apply K-Means Clustering","metadata":{}},{"cell_type":"code","source":"# standardize features\nscaler = StandardScaler()\nfeatures_scaled = scaler.fit_transform(game_features_filtered)\n\n# elbow method to find optimal k\ninertias = []\nk_range = range(2, 11)\nfor k in k_range:\n    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n    kmeans.fit(features_scaled)\n    inertias.append(kmeans.inertia_)\n\nplt.figure(figsize=(10, 6))\nplt.plot(k_range, inertias, marker='o', linewidth=2)\nplt.xlabel('Number of Clusters (k)')\nplt.ylabel('Inertia')\nplt.title('Elbow Method for Optimal k')\nplt.grid(True, alpha=0.3)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T00:19:36.165444Z","iopub.execute_input":"2025-11-05T00:19:36.165707Z","iopub.status.idle":"2025-11-05T00:19:37.107977Z","shell.execute_reply.started":"2025-11-05T00:19:36.165687Z","shell.execute_reply":"2025-11-05T00:19:37.107063Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# use k=5 clusters based on elbow\nn_clusters = 5\nkmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\ngame_features_filtered['cluster'] = kmeans.fit_predict(features_scaled)\n\nprint(f\"Cluster distribution:\")\nprint(game_features_filtered['cluster'].value_counts().sort_index())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T00:19:47.237697Z","iopub.execute_input":"2025-11-05T00:19:47.237981Z","iopub.status.idle":"2025-11-05T00:19:47.307143Z","shell.execute_reply.started":"2025-11-05T00:19:47.237962Z","shell.execute_reply":"2025-11-05T00:19:47.306064Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Analyze Clusters","metadata":{}},{"cell_type":"code","source":"# cluster characteristics\ncluster_summary = game_features_filtered.groupby('cluster').agg({\n    'mean_players': 'mean',\n    'max_players': 'mean',\n    'cv': 'mean',\n    'growth_rate': 'mean',\n    'months_declining': 'mean',\n    'final_to_peak_ratio': 'mean',\n    'total_months': 'mean'\n}).round(2)\n\nprint(\"Cluster Characteristics:\")\nprint(cluster_summary)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T00:20:04.969245Z","iopub.execute_input":"2025-11-05T00:20:04.969557Z","iopub.status.idle":"2025-11-05T00:20:04.984424Z","shell.execute_reply.started":"2025-11-05T00:20:04.969532Z","shell.execute_reply":"2025-11-05T00:20:04.983564Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# visualize clusters in 2D (using PCA-like approach)\nfrom sklearn.decomposition import PCA\n\npca = PCA(n_components=2)\nfeatures_2d = pca.fit_transform(features_scaled)\n\nplt.figure(figsize=(12, 8))\nscatter = plt.scatter(features_2d[:, 0], features_2d[:, 1], \n                     c=game_features_filtered['cluster'], cmap='viridis', \n                     alpha=0.6, s=50)\nplt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\nplt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')\nplt.title('Game Clusters Visualization (PCA)')\nplt.colorbar(scatter, label='Cluster')\nplt.grid(True, alpha=0.3)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T00:20:14.679969Z","iopub.execute_input":"2025-11-05T00:20:14.680267Z","iopub.status.idle":"2025-11-05T00:20:14.991148Z","shell.execute_reply.started":"2025-11-05T00:20:14.680247Z","shell.execute_reply":"2025-11-05T00:20:14.990422Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# show example games from each cluster\nfor cluster_id in range(n_clusters):\n    print(f\"\\nCluster {cluster_id} - Top 5 games by avg players:\")\n    cluster_games = game_features_filtered[game_features_filtered['cluster'] == cluster_id]\n    top_games = cluster_games.nlargest(5, 'mean_players')\n    for idx, row in top_games.iterrows():\n        print(f\"  {idx}: {row['mean_players']:.0f} avg players\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T00:20:21.841104Z","iopub.execute_input":"2025-11-05T00:20:21.842378Z","iopub.status.idle":"2025-11-05T00:20:21.856206Z","shell.execute_reply.started":"2025-11-05T00:20:21.842324Z","shell.execute_reply":"2025-11-05T00:20:21.855447Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. Next-Month Player Prediction (Regression)\n\nPredict player count for the next month based on recent trends.","metadata":{}},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{}},{"cell_type":"code","source":"# create lag features and rolling stats for each game\ndef create_prediction_features(group):\n    group = group.sort_values('date').copy()\n    \n    # lag features\n    for i in [1, 2, 3, 6]:\n        group[f'avg_players_lag_{i}'] = group['avg_players'].shift(i)\n        group[f'gain_lag_{i}'] = group['gain'].shift(i)\n    \n    # rolling statistics\n    group['avg_players_roll_3'] = group['avg_players'].rolling(3, min_periods=1).mean()\n    group['avg_players_roll_6'] = group['avg_players'].rolling(6, min_periods=1).mean()\n    group['gain_roll_3'] = group['gain'].rolling(3, min_periods=1).mean()\n    \n    # trend features\n    group['trend'] = group['avg_players'].pct_change()\n    group['momentum'] = group['gain'].rolling(3, min_periods=1).mean()\n    \n    return group\n\ndf_features = df.groupby('steam_appid').apply(create_prediction_features).reset_index(drop=True)\nprint(f\"Created features: {len(df_features)} records\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T00:20:54.540829Z","iopub.execute_input":"2025-11-05T00:20:54.541153Z","iopub.status.idle":"2025-11-05T00:21:21.534222Z","shell.execute_reply.started":"2025-11-05T00:20:54.541133Z","shell.execute_reply":"2025-11-05T00:21:21.533564Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# add time-based features\ndf_features['month_sin'] = np.sin(2 * np.pi * df_features['month_num'] / 12)\ndf_features['month_cos'] = np.cos(2 * np.pi * df_features['month_num'] / 12)\n\n# target: next month's player count\ndf_features['target'] = df_features.groupby('steam_appid')['avg_players'].shift(-1)\n\n# drop rows with missing values\ndf_ml = df_features.dropna(subset=['target']).copy()\nprint(f\"Final dataset: {len(df_ml)} records\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T00:22:00.390548Z","iopub.execute_input":"2025-11-05T00:22:00.390801Z","iopub.status.idle":"2025-11-05T00:22:00.490541Z","shell.execute_reply.started":"2025-11-05T00:22:00.390777Z","shell.execute_reply":"2025-11-05T00:22:00.48966Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Train Regression Models","metadata":{}},{"cell_type":"code","source":"# select features\nfeature_cols = ['avg_players', 'avg_players_lag_1', 'avg_players_lag_2', 'avg_players_lag_3',\n                'gain_lag_1', 'gain_lag_2', 'avg_players_roll_3', 'avg_players_roll_6',\n                'gain_roll_3', 'momentum', 'month_sin', 'month_cos']\n\n# drop rows with NaN in ANY of our feature columns or target\ndf_ml_clean = df_ml[feature_cols + ['target', 'date']].dropna().copy()\n\nX = df_ml_clean[feature_cols]\ny = df_ml_clean['target']\n\nprint(f\"After removing NaNs: {len(X)} records\")\n\n# temporal split - train on older data, test on recent\nsplit_date = df_ml_clean['date'].quantile(0.8)\ntrain_mask = df_ml_clean['date'] <= split_date\ntest_mask = df_ml_clean['date'] > split_date\n\nX_train = X[train_mask]\nX_test = X[test_mask]\ny_train = y[train_mask]\ny_test = y[test_mask]\n\nprint(f\"Train set: {len(X_train)} records\")\nprint(f\"Test set: {len(X_test)} records\")\nprint(f\"Split date: {split_date}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T00:26:45.388142Z","iopub.execute_input":"2025-11-05T00:26:45.388406Z","iopub.status.idle":"2025-11-05T00:26:45.485848Z","shell.execute_reply.started":"2025-11-05T00:26:45.388382Z","shell.execute_reply":"2025-11-05T00:26:45.485206Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# try multiple models\nmodels = {\n    'Linear Regression': LinearRegression(),\n    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n}\n\nresults = {}\nfor name, model in models.items():\n    print(f\"\\nTraining {name}...\")\n    model.fit(X_train, y_train)\n    \n    y_pred = model.predict(X_test)\n    \n    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n    mae = mean_absolute_error(y_test, y_pred)\n    r2 = r2_score(y_test, y_pred)\n    \n    results[name] = {'RMSE': rmse, 'MAE': mae, 'R2': r2, 'model': model}\n    \n    print(f\"  RMSE: {rmse:.2f}\")\n    print(f\"  MAE: {mae:.2f}\")\n    print(f\"  R²: {r2:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T00:26:48.987536Z","iopub.execute_input":"2025-11-05T00:26:48.987775Z","iopub.status.idle":"2025-11-05T00:31:33.039546Z","shell.execute_reply.started":"2025-11-05T00:26:48.98776Z","shell.execute_reply":"2025-11-05T00:31:33.038883Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# visualize predictions vs actual\nbest_model_name = min(results.keys(), key=lambda k: results[k]['RMSE'])\nbest_model = results[best_model_name]['model']\ny_pred = best_model.predict(X_test)\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# scatter plot\naxes[0].scatter(y_test, y_pred, alpha=0.5)\naxes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\naxes[0].set_xlabel('Actual Players')\naxes[0].set_ylabel('Predicted Players')\naxes[0].set_title(f'{best_model_name} - Predictions vs Actual')\naxes[0].set_xscale('log')\naxes[0].set_yscale('log')\n\n# residuals\nresiduals = y_test - y_pred\naxes[1].scatter(y_pred, residuals, alpha=0.5)\naxes[1].axhline(y=0, color='r', linestyle='--', lw=2)\naxes[1].set_xlabel('Predicted Players')\naxes[1].set_ylabel('Residuals')\naxes[1].set_title('Residual Plot')\naxes[1].set_xscale('log')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T00:31:33.987486Z","iopub.execute_input":"2025-11-05T00:31:33.988529Z","iopub.status.idle":"2025-11-05T00:31:34.915222Z","shell.execute_reply.started":"2025-11-05T00:31:33.988496Z","shell.execute_reply":"2025-11-05T00:31:34.914227Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# feature importance (for Random Forest)\nif 'Random Forest' in results:\n    rf_model = results['Random Forest']['model']\n    feature_importance = pd.DataFrame({\n        'feature': feature_cols,\n        'importance': rf_model.feature_importances_\n    }).sort_values('importance', ascending=False)\n    \n    plt.figure(figsize=(10, 6))\n    plt.barh(feature_importance['feature'], feature_importance['importance'])\n    plt.xlabel('Importance')\n    plt.title('Feature Importance - Random Forest')\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T00:54:58.576251Z","iopub.execute_input":"2025-11-05T00:54:58.577286Z","iopub.status.idle":"2025-11-05T00:54:59.456166Z","shell.execute_reply.started":"2025-11-05T00:54:58.577267Z","shell.execute_reply":"2025-11-05T00:54:59.455348Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### True Forecasting Challenge - Predict Without Current Month Data\n\nThe above model achieved ~99% R² because it used current month's player count to predict next month. While accurate, this is somewhat trivial since player counts are sticky.\n\nLet's make it harder: **predict next month using ONLY historical data (no current month)**. This is true forecasting.","metadata":{}},{"cell_type":"code","source":"# remove current month from features - only use historical lags\nforecast_feature_cols = ['avg_players_lag_1', 'avg_players_lag_2', 'avg_players_lag_3',\n                         'gain_lag_1', 'gain_lag_2', 'avg_players_roll_3', 'avg_players_roll_6',\n                         'gain_roll_3', 'momentum', 'month_sin', 'month_cos']\n\n# use same cleaned dataset\nX_forecast = df_ml_clean[forecast_feature_cols].reset_index(drop=True)\ny_forecast = df_ml_clean['target'].reset_index(drop=True)\ndates = df_ml_clean['date'].reset_index(drop=True)\n\n# recreate temporal split with aligned indices\ntrain_mask_f = dates <= split_date\ntest_mask_f = dates > split_date\n\nX_train_f = X_forecast[train_mask_f]\nX_test_f = X_forecast[test_mask_f]\ny_train_f = y_forecast[train_mask_f]\ny_test_f = y_forecast[test_mask_f]\n\nprint(f\"True Forecasting - Train: {len(X_train_f)}, Test: {len(X_test_f)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T01:07:03.926766Z","iopub.execute_input":"2025-11-05T01:07:03.927027Z","iopub.status.idle":"2025-11-05T01:07:03.98942Z","shell.execute_reply.started":"2025-11-05T01:07:03.927011Z","shell.execute_reply":"2025-11-05T01:07:03.988645Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train models for true forecasting\nforecast_models = {\n    'Linear Regression': LinearRegression(),\n    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n}\n\nforecast_results = {}\nfor name, model in forecast_models.items():\n    print(f\"\\nTraining {name} (No Current Month)...\")\n    model.fit(X_train_f, y_train_f)\n    \n    y_pred_f = model.predict(X_test_f)\n    \n    rmse = np.sqrt(mean_squared_error(y_test_f, y_pred_f))\n    mae = mean_absolute_error(y_test_f, y_pred_f)\n    r2 = r2_score(y_test_f, y_pred_f)\n    \n    forecast_results[name] = {'RMSE': rmse, 'MAE': mae, 'R2': r2, 'model': model}\n    \n    print(f\"  RMSE: {rmse:.2f}\")\n    print(f\"  MAE: {mae:.2f}\")\n    print(f\"  R²: {r2:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T01:07:56.346642Z","iopub.execute_input":"2025-11-05T01:07:56.347572Z","iopub.status.idle":"2025-11-05T01:12:21.488101Z","shell.execute_reply.started":"2025-11-05T01:07:56.347537Z","shell.execute_reply":"2025-11-05T01:12:21.487177Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# compare baseline vs true forecasting\ncomparison_data = []\nfor name in ['Linear Regression', 'Random Forest']:\n    comparison_data.append({\n        'Model': f\"{name}\\n(with current month)\",\n        'R²': results[name]['R2'],\n        'MAE': results[name]['MAE']\n    })\n    comparison_data.append({\n        'Model': f\"{name}\\n(historical only)\",\n        'R²': forecast_results[name]['R2'],\n        'MAE': forecast_results[name]['MAE']\n    })\n\ncomparison_df = pd.DataFrame(comparison_data)\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# R² comparison\nx_pos = np.arange(len(comparison_df))\ncolors = ['#1f77b4', '#ff7f0e', '#1f77b4', '#ff7f0e']\naxes[0].bar(x_pos, comparison_df['R²'], color=colors, alpha=0.7, edgecolor='black')\naxes[0].set_xticks(x_pos)\naxes[0].set_xticklabels(comparison_df['Model'], fontsize=9)\naxes[0].set_ylabel('R² Score')\naxes[0].set_title('Model Comparison - R² Score')\naxes[0].set_ylim([0, 1])\naxes[0].grid(True, alpha=0.3, axis='y')\n\n# MAE comparison\naxes[1].bar(x_pos, comparison_df['MAE'], color=colors, alpha=0.7, edgecolor='black')\naxes[1].set_xticks(x_pos)\naxes[1].set_xticklabels(comparison_df['Model'], fontsize=9)\naxes[1].set_ylabel('Mean Absolute Error')\naxes[1].set_title('Model Comparison - MAE (Lower is Better)')\naxes[1].grid(True, alpha=0.3, axis='y')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T01:12:22.227974Z","iopub.execute_input":"2025-11-05T01:12:22.228271Z","iopub.status.idle":"2025-11-05T01:12:22.499684Z","shell.execute_reply.started":"2025-11-05T01:12:22.228245Z","shell.execute_reply":"2025-11-05T01:12:22.498864Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# feature importance for true forecasting\nrf_forecast = forecast_results['Random Forest']['model']\nfeature_importance_forecast = pd.DataFrame({\n    'feature': forecast_feature_cols,\n    'importance': rf_forecast.feature_importances_\n}).sort_values('importance', ascending=False)\n\nplt.figure(figsize=(10, 6))\nplt.barh(feature_importance_forecast['feature'], feature_importance_forecast['importance'])\nplt.xlabel('Importance')\nplt.title('Feature Importance - True Forecasting (Historical Data Only)')\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nTop 5 Most Important Features:\")\nprint(feature_importance_forecast.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T01:13:25.200637Z","iopub.execute_input":"2025-11-05T01:13:25.200927Z","iopub.status.idle":"2025-11-05T01:13:25.527015Z","shell.execute_reply.started":"2025-11-05T01:13:25.20091Z","shell.execute_reply":"2025-11-05T01:13:25.526047Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# generate predictions from the best model\nbest_forecast_model = forecast_results['Random Forest']['model']\ny_pred_forecast = best_forecast_model.predict(X_test_f)\n\nprint(f\"Generated {len(y_pred_forecast)} predictions\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T01:17:05.946617Z","iopub.execute_input":"2025-11-05T01:17:05.947213Z","iopub.status.idle":"2025-11-05T01:17:07.903837Z","shell.execute_reply.started":"2025-11-05T01:17:05.947194Z","shell.execute_reply":"2025-11-05T01:17:07.90318Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# better approach - keep game identifiers throughout\n# recreate test set with all needed columns from df_ml\ntest_cols = ['date', 'steam_appid'] + forecast_feature_cols + ['target']\ntest_full_data = df_ml[test_cols].dropna()\n\n# recreate the clean dataset with steam_appid\ntest_full_data_clean = test_full_data[test_full_data['date'] > split_date].copy()\n\n# get predictions for this test set\nX_test_viz = test_full_data_clean[forecast_feature_cols]\ny_test_viz = test_full_data_clean['target']\ny_pred_viz = best_forecast_model.predict(X_test_viz)\n\n# create results dataframe\ntest_results = test_full_data_clean[['date', 'steam_appid']].copy()\ntest_results['actual'] = y_test_viz.values\ntest_results['predicted'] = y_pred_viz\n\n# merge with game names\ntest_results = test_results.merge(df[['steam_appid', 'name']].drop_duplicates(), on='steam_appid', how='left')\n\nprint(f\"Test results: {len(test_results)} predictions\")\nprint(f\"Unique games: {test_results['name'].nunique()}\")\nprint(f\"Sample games: {test_results['name'].value_counts().head()}\")\n\n# visualize\ngames_to_visualize = ['PUBG: BATTLEGROUNDS', 'Counter-Strike 2', 'Dota 2', 'Rust']\n\nfig, axes = plt.subplots(len(games_to_visualize), 1, figsize=(14, 12))\n\nfor idx, game in enumerate(games_to_visualize):\n    game_full = df[df['name'] == game].sort_values('date')\n    game_test = test_results[test_results['name'] == game].sort_values('date')\n    \n    if len(game_full) > 0:\n        axes[idx].plot(game_full['date'], game_full['avg_players'], \n                      label='Actual (Full History)', linewidth=2, color='blue', alpha=0.7)\n        \n        if len(game_test) > 0:\n            axes[idx].plot(game_test['date'], game_test['predicted'], \n                          label='Model Prediction', linewidth=2.5, \n                          color='red', linestyle='--', marker='o', markersize=4)\n            print(f\"{game}: {len(game_test)} test predictions\")\n        else:\n            print(f\"{game}: NO test predictions found\")\n        \n        axes[idx].axvline(x=split_date, color='green', linestyle=':', linewidth=2, label='Train/Test Split')\n        axes[idx].set_ylabel('Average Players')\n        axes[idx].set_title(f'{game} - Time Series: Actual vs Predicted')\n        axes[idx].legend(loc='best')\n        axes[idx].grid(True, alpha=0.3)\n    else:\n        axes[idx].text(0.5, 0.5, f'{game} - No data available', \n                      ha='center', va='center', transform=axes[idx].transAxes)\n\naxes[-1].set_xlabel('Date')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T01:19:02.377785Z","iopub.execute_input":"2025-11-05T01:19:02.378102Z","iopub.status.idle":"2025-11-05T01:19:05.427293Z","shell.execute_reply.started":"2025-11-05T01:19:02.378083Z","shell.execute_reply":"2025-11-05T01:19:05.426588Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# TOP 5 GAMES VISUALIZATION\nprint(\"=\"*60)\nprint(\"TOP 5 GAMES - ACTUAL VS PREDICTED\")\nprint(\"=\"*60)\n\n# get top 5 games by average player count\ntop_5_games = df.groupby('name')['avg_players'].mean().nlargest(5).index.tolist()\nprint(f\"\\nTop 5 games by average player count:\")\nfor i, game in enumerate(top_5_games, 1):\n    avg = df[df['name'] == game]['avg_players'].mean()\n    print(f\"  {i}. {game}: {avg:,.0f} avg players\")\n\n# visualize top 5\nfig, axes = plt.subplots(len(top_5_games), 1, figsize=(14, 14))\n\nfor idx, game in enumerate(top_5_games):\n    game_full = df[df['name'] == game].sort_values('date')\n    game_test = test_results[test_results['name'] == game].sort_values('date')\n    \n    if len(game_full) > 0:\n        axes[idx].plot(game_full['date'], game_full['avg_players'], \n                      label='Actual (Full History)', linewidth=2, color='blue', alpha=0.7)\n        \n        if len(game_test) > 0:\n            axes[idx].plot(game_test['date'], game_test['predicted'], \n                          label='Model Prediction', linewidth=2.5, \n                          color='red', linestyle='--', marker='o', markersize=4)\n            \n            # calculate accuracy for this game\n            game_mae = np.abs(game_test['actual'] - game_test['predicted']).mean()\n            game_mape = (np.abs((game_test['actual'] - game_test['predicted']) / (game_test['actual'] + 1)).mean() * 100)\n            print(f\"\\n{game}:\")\n            print(f\"  Test predictions: {len(game_test)}\")\n            print(f\"  MAE: {game_mae:.2f} players\")\n            print(f\"  MAPE: {game_mape:.2f}%\")\n        \n        axes[idx].axvline(x=split_date, color='green', linestyle=':', linewidth=2, \n                         label='Train/Test Split', alpha=0.6)\n        axes[idx].set_ylabel('Average Players')\n        axes[idx].set_title(f'#{idx+1}: {game} - Actual vs Predicted Player Counts')\n        axes[idx].legend(loc='best')\n        axes[idx].grid(True, alpha=0.3)\n\naxes[-1].set_xlabel('Date')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T01:20:37.643274Z","iopub.execute_input":"2025-11-05T01:20:37.643534Z","iopub.status.idle":"2025-11-05T01:20:38.997971Z","shell.execute_reply.started":"2025-11-05T01:20:37.643517Z","shell.execute_reply":"2025-11-05T01:20:38.997176Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# analyze what's ACTUALLY driving the predictions\nprint(\"=\"*60)\nprint(\"WHAT'S REALLY PREDICTING THE FUTURE?\")\nprint(\"=\"*60)\n\n# look at correlation between features and target in test set\ntest_correlations = pd.DataFrame({\n    'feature': forecast_feature_cols,\n    'correlation_with_target': [test_full_data_clean[col].corr(test_full_data_clean['target']) \n                                for col in forecast_feature_cols]\n}).sort_values('correlation_with_target', ascending=False)\n\nprint(\"\\nCorrelation with Next Month's Player Count:\")\nprint(test_correlations)\n\n# check autocorrelation\nprint(\"\\n\" + \"=\"*60)\nprint(\"AUTOCORRELATION TEST\")\nprint(\"=\"*60)\nsample_game = 'Counter-Strike 2'\ngame_data = df[df['name'] == sample_game].sort_values('date')[['date', 'avg_players']].tail(50)\ngame_data['next_month'] = game_data['avg_players'].shift(-1)\ncorrelation = game_data['avg_players'].corr(game_data['next_month'])\nprint(f\"\\n{sample_game}:\")\nprint(f\"Correlation between this month and next month: {correlation:.4f}\")\nprint(f\"This means: {correlation**2:.2%} of next month's value is explained by this month!\")\n\n# show the \"naive\" baseline\nprint(\"\\n\" + \"=\"*60)\nprint(\"NAIVE BASELINE COMPARISON\")\nprint(\"=\"*60)\nprint(\"What if we just predicted: next_month = last_month?\")\nnaive_predictions = test_full_data_clean['avg_players_lag_1']\nnaive_mae = mean_absolute_error(y_test_viz, naive_predictions)\nnaive_rmse = np.sqrt(mean_squared_error(y_test_viz, naive_predictions))\nnaive_r2 = r2_score(y_test_viz, naive_predictions)\n\nprint(f\"\\nNaive Model (just use lag_1 as prediction):\")\nprint(f\"  MAE: {naive_mae:.2f}\")\nprint(f\"  RMSE: {naive_rmse:.2f}\")\nprint(f\"  R²: {naive_r2:.4f}\")\n\nprint(f\"\\nOur Random Forest Model:\")\nprint(f\"  MAE: {forecast_results['Random Forest']['MAE']:.2f}\")\nprint(f\"  RMSE: {forecast_results['Random Forest']['RMSE']:.2f}\")\nprint(f\"  R²: {forecast_results['Random Forest']['R2']:.4f}\")\n\nprint(f\"\\nImprovement over naive baseline:\")\nprint(f\"  MAE improvement: {((naive_mae - forecast_results['Random Forest']['MAE']) / naive_mae * 100):.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-05T01:23:00.897509Z","iopub.execute_input":"2025-11-05T01:23:00.898155Z","iopub.status.idle":"2025-11-05T01:23:00.959657Z","shell.execute_reply.started":"2025-11-05T01:23:00.898133Z","shell.execute_reply":"2025-11-05T01:23:00.958974Z"}},"outputs":[],"execution_count":null}]}