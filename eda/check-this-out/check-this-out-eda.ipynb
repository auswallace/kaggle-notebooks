{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14491266,"sourceType":"datasetVersion","datasetId":9187454}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-02T19:27:29.837749Z","iopub.execute_input":"2026-02-02T19:27:29.838108Z","iopub.status.idle":"2026-02-02T19:27:29.850336Z","shell.execute_reply.started":"2026-02-02T19:27:29.838077Z","shell.execute_reply":"2026-02-02T19:27:29.849035Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ğŸ“± The Instagram Behavioral Genome\n## Decoding 1 Million User Profiles: Where Digital Habits Meet Real Life\n\n<div style=\"background: linear-gradient(135deg, #833ab4, #fd1d1d, #fcb045); padding: 2px; border-radius: 12px; margin: 20px 0;\">\n<div style=\"background: #0d1117; padding: 24px; border-radius: 11px; color: #c9d1d9;\">\n<b>Dataset:</b> 1M synthetic Instagram user profiles (2025â€“2026) with 57 features spanning demographics, lifestyle, health metrics, and platform engagement. This EDA uses advanced visualization and unsupervised learning to uncover the hidden architecture of social media behavior.\n</div>\n</div>\n\n---\n**Techniques:** UMAP Embeddings Â· Hierarchical Clustering Â· Kernel Density Estimation Â· Ridge Plots Â· Radar Profiles Â· Network Correlation Graphs Â· Interactive Plotly Charts\n","metadata":{}},{"cell_type":"markdown","source":"## âš™ï¸ Environment Setup & Data Ingestion","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\nimport matplotlib.patheffects as pe\nfrom matplotlib.gridspec import GridSpec\nfrom matplotlib.colors import LinearSegmentedColormap, to_rgba\nfrom matplotlib.patches import FancyBboxPatch\nimport seaborn as sns\nfrom scipy import stats\nfrom scipy.cluster.hierarchy import linkage, dendrogram, fcluster\nfrom scipy.spatial.distance import pdist\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom sklearn.manifold import TSNE\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport colorsys\n\n# â”€â”€ Master Theme â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nPALETTE = {\n    'bg':       '#0d1117',\n    'card':     '#161b22',\n    'grid':     '#21262d',\n    'text':     '#c9d1d9',\n    'muted':    '#8b949e',\n    'accent1':  '#833ab4',   # Instagram purple\n    'accent2':  '#fd1d1d',   # Instagram red\n    'accent3':  '#fcb045',   # Instagram gold\n    'accent4':  '#00d2ff',   # Cyan\n    'accent5':  '#3a86ff',   # Blue\n    'accent6':  '#06d6a0',   # Mint\n    'accent7':  '#ef476f',   # Pink\n    'accent8':  '#ffd166',   # Yellow\n}\n\nIG_GRADIENT = ['#833ab4', '#c13584', '#e1306c', '#fd1d1d', '#f56040', '#fcb045']\nNEON_SEQ = [PALETTE['accent4'], PALETTE['accent5'], PALETTE['accent6'],\n            PALETTE['accent7'], PALETTE['accent8'], PALETTE['accent1']]\n\ndef set_dark_theme():\n    plt.rcParams.update({\n        'figure.facecolor':     PALETTE['bg'],\n        'axes.facecolor':       PALETTE['card'],\n        'axes.edgecolor':       PALETTE['grid'],\n        'axes.labelcolor':      PALETTE['text'],\n        'text.color':           PALETTE['text'],\n        'xtick.color':          PALETTE['muted'],\n        'ytick.color':          PALETTE['muted'],\n        'grid.color':           PALETTE['grid'],\n        'grid.alpha':           0.3,\n        'font.family':          'monospace',\n        'font.size':            11,\n        'axes.titlesize':       14,\n        'axes.titleweight':     'bold',\n        'figure.titlesize':     18,\n        'figure.titleweight':   'bold',\n        'legend.facecolor':     PALETTE['card'],\n        'legend.edgecolor':     PALETTE['grid'],\n        'legend.fontsize':      9,\n        'savefig.facecolor':    PALETTE['bg'],\n        'savefig.edgecolor':    PALETTE['bg'],\n    })\nset_dark_theme()\n\ndef gradient_text(ax, x, y, text, fontsize=18, fw='bold'):\n    \"\"\"Simulated gradient title using path effects.\"\"\"\n    ax.text(x, y, text, fontsize=fontsize, fontweight=fw,\n            color=PALETTE['accent3'],\n            path_effects=[pe.withStroke(linewidth=2, foreground=PALETTE['accent1'])],\n            transform=ax.transAxes, va='top')\n\ndef add_watermark(fig):\n    fig.text(0.99, 0.01, 'Instagram Behavioral Genome Â· 1M Users',\n             fontsize=7, color=PALETTE['muted'], alpha=0.4,\n             ha='right', va='bottom', style='italic')\n\nprint(\"âœ… Theme engine loaded â€” dark mode activated\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T19:27:29.852525Z","iopub.execute_input":"2026-02-02T19:27:29.852955Z","iopub.status.idle":"2026-02-02T19:27:29.875072Z","shell.execute_reply.started":"2026-02-02T19:27:29.852922Z","shell.execute_reply":"2026-02-02T19:27:29.873653Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ğŸ“¥ Load the Dataset","metadata":{}},{"cell_type":"code","source":"import os\nimport glob\n\n# â”€â”€ Load from Kaggle input paths â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ndata_dir = '/kaggle/input/social-media-user-analysis/'\nfiles = sorted(glob.glob(os.path.join(data_dir, '*.csv')))\nprint(f\"ğŸ“‚ Files found: {files}\")\n\n# Load both CSVs and combine if they share the same schema\ndfs = []\nfor f in sorted(files):\n    print(f\"  â³ Loading {os.path.basename(f)}...\")\n    tmp = pd.read_csv(f)\n    print(f\"     â†’ {tmp.shape[0]:,} rows Ã— {tmp.shape[1]} cols\")\n    dfs.append(tmp)\n\nif len(dfs) == 2 and list(dfs[0].columns) == list(dfs[1].columns):\n    df = pd.concat(dfs, ignore_index=True)\n    print(f\"\\nğŸ”— Combined both files (identical schemas)\")\nelif len(dfs) == 2:\n    # Different schemas â€” use the larger file\n    df = max(dfs, key=len)\n    print(f\"\\nâš ï¸ Different schemas detected â€” using the larger file\")\nelse:\n    df = dfs[0]\n\nprint(f\"\\nğŸ”¢ Final shape: {df.shape[0]:,} rows Ã— {df.shape[1]} columns\")\nprint(f\"ğŸ’¾ Memory: {df.memory_usage(deep=True).sum() / 1e6:.1f} MB\")\ndf.head(3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T19:27:29.876497Z","iopub.execute_input":"2026-02-02T19:27:29.876906Z","iopub.status.idle":"2026-02-02T19:28:06.294582Z","shell.execute_reply.started":"2026-02-02T19:27:29.876875Z","shell.execute_reply":"2026-02-02T19:28:06.293662Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ğŸ” Section 1 â€” Data Profiling at a Glance\n> A rapid structural audit: types, nulls, cardinality, and distributional fingerprints.\n","metadata":{}},{"cell_type":"code","source":"# â”€â”€ Structural overview â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nprofile = pd.DataFrame({\n    'dtype': df.dtypes,\n    'non_null': df.notnull().sum(),\n    'null_pct': (df.isnull().sum() / len(df) * 100).round(2),\n    'unique': df.nunique(),\n    'sample': df.iloc[0],\n})\nprint(profile.to_string())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T19:28:06.296018Z","iopub.execute_input":"2026-02-02T19:28:06.29635Z","iopub.status.idle":"2026-02-02T19:28:18.035769Z","shell.execute_reply.started":"2026-02-02T19:28:06.296319Z","shell.execute_reply":"2026-02-02T19:28:18.03458Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# â”€â”€ Numeric summary heatmap â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nnum_cols = df.select_dtypes(include='number').columns.tolist()\ndesc = df[num_cols].describe().T\n\nfig, ax = plt.subplots(figsize=(16, max(8, len(num_cols)*0.35)))\ncmap = LinearSegmentedColormap.from_list('ig', [PALETTE['accent1'], PALETTE['bg'], PALETTE['accent3']])\n\nnormed = desc.copy()\nfor col in desc.columns:\n    mn, mx = desc[col].min(), desc[col].max()\n    normed[col] = (desc[col] - mn) / (mx - mn + 1e-9)\n\nim = ax.imshow(normed.values, aspect='auto', cmap=cmap, alpha=0.85)\n\nax.set_yticks(range(len(desc.index)))\nax.set_yticklabels(desc.index, fontsize=8)\nax.set_xticks(range(len(desc.columns)))\nax.set_xticklabels(desc.columns, fontsize=9, rotation=0)\n\nfor i in range(len(desc.index)):\n    for j in range(len(desc.columns)):\n        val = desc.iloc[i, j]\n        txt = f'{val:.1f}' if abs(val) < 1000 else f'{val:.0f}'\n        ax.text(j, i, txt, ha='center', va='center', fontsize=6.5, color=PALETTE['text'])\n\nax.set_title('Numeric Feature Statistics â€” Normalized Heatmap', pad=15)\nadd_watermark(fig)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T19:28:18.037961Z","iopub.execute_input":"2026-02-02T19:28:18.038304Z","iopub.status.idle":"2026-02-02T19:28:25.778285Z","shell.execute_reply.started":"2026-02-02T19:28:18.038275Z","shell.execute_reply":"2026-02-02T19:28:25.777358Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ğŸ“Š Section 2 â€” Distribution Landscape\n> Ridge plots and layered KDE to reveal the shape of each feature's universe.\n","metadata":{}},{"cell_type":"code","source":"# â”€â”€ Instagram Metrics Ridge Plot â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nig_time_cols = ['time_on_feed_per_day', 'time_on_explore_per_day',\n                'time_on_messages_per_day', 'time_on_reels_per_day',\n                'daily_active_minutes_instagram']\n\nfig, axes = plt.subplots(len(ig_time_cols), 1, figsize=(14, 10),\n                          sharex=False)\nfig.suptitle('Time Allocation Across Instagram Surfaces',\n             fontsize=18, fontweight='bold', y=1.02,\n             color=PALETTE['accent3'])\n\nfor i, col in enumerate(ig_time_cols):\n    ax = axes[i]\n    data = df[col].dropna()\n\n    # KDE\n    from scipy.stats import gaussian_kde\n    x_range = np.linspace(data.quantile(0.001), data.quantile(0.999), 500)\n    kde = gaussian_kde(data.sample(min(50000, len(data)), random_state=42))\n    density = kde(x_range)\n\n    # Gradient fill\n    color = IG_GRADIENT[i % len(IG_GRADIENT)]\n    ax.fill_between(x_range, density, alpha=0.4, color=color)\n    ax.plot(x_range, density, color=color, lw=2.5,\n            path_effects=[pe.withStroke(linewidth=4, foreground=PALETTE['bg'])])\n\n    # Stats annotation\n    med = data.median()\n    ax.axvline(med, color=PALETTE['accent4'], ls='--', lw=1, alpha=0.7)\n    ax.text(0.98, 0.85, f'median={med:.1f}  Î¼={data.mean():.1f}  Ïƒ={data.std():.1f}',\n            transform=ax.transAxes, ha='right', fontsize=8,\n            color=PALETTE['muted'], family='monospace')\n\n    ax.set_ylabel(col.replace('_', ' ').title(), fontsize=8, rotation=0,\n                  labelpad=120, va='center')\n    ax.set_yticks([])\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.spines['left'].set_visible(False)\n\nadd_watermark(fig)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T19:28:25.779471Z","iopub.execute_input":"2026-02-02T19:28:25.779873Z","iopub.status.idle":"2026-02-02T19:28:30.042868Z","shell.execute_reply.started":"2026-02-02T19:28:25.779834Z","shell.execute_reply":"2026-02-02T19:28:30.041946Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# â”€â”€ Age Distribution with Generational Bands â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nfig, ax = plt.subplots(figsize=(14, 6))\n\nage_data = df['age'].dropna()\nbins = np.arange(age_data.min()-0.5, age_data.max()+1.5, 1)\nn, bins_out, patches = ax.hist(age_data, bins=bins, density=True,\n                                 alpha=0.7, edgecolor='none')\n\n# Color by generation\ngen_bands = [\n    (13, 27, 'Gen Z',       PALETTE['accent4']),\n    (28, 43, 'Millennial',  PALETTE['accent1']),\n    (44, 59, 'Gen X',       PALETTE['accent3']),\n    (60, 80, 'Boomer',      PALETTE['accent7']),\n]\nfor patch, left in zip(patches, bins_out[:-1]):\n    age_val = left + 0.5\n    for lo, hi, label, col in gen_bands:\n        if lo <= age_val <= hi:\n            patch.set_facecolor(col)\n            break\n\n# KDE overlay\nfrom scipy.stats import gaussian_kde\nx_kde = np.linspace(age_data.min(), age_data.max(), 300)\nkde = gaussian_kde(age_data.sample(50000, random_state=42))\nax.plot(x_kde, kde(x_kde), color='white', lw=2.5, alpha=0.9)\n\n# Generation labels\nfor lo, hi, label, col in gen_bands:\n    mid = (lo + hi) / 2\n    ax.text(mid, ax.get_ylim()[1]*0.92, label, ha='center', fontsize=11,\n            fontweight='bold', color=col, alpha=0.9)\n\nax.set_title('Age Distribution with Generational Segments', pad=15)\nax.set_xlabel('Age')\nax.set_ylabel('Density')\nadd_watermark(fig)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T19:28:30.04404Z","iopub.execute_input":"2026-02-02T19:28:30.044669Z","iopub.status.idle":"2026-02-02T19:28:30.842426Z","shell.execute_reply.started":"2026-02-02T19:28:30.044602Z","shell.execute_reply":"2026-02-02T19:28:30.841452Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ğŸŒ Section 3 â€” Demographic Landscape\n> Who are these 1 million users? Gender splits, geography, income tiers, and how they intersect with Instagram engagement.\n","metadata":{}},{"cell_type":"code","source":"# â”€â”€ Engagement by Demographics â€” Multi-panel â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nfig = plt.figure(figsize=(18, 12))\ngs = GridSpec(2, 3, figure=fig, hspace=0.35, wspace=0.3)\n\n# 1. Gender Ã— Daily Minutes\nax1 = fig.add_subplot(gs[0, 0])\nif 'gender' in df.columns:\n    gender_order = df['gender'].value_counts().index.tolist()\n    colors_g = [PALETTE['accent7'], PALETTE['accent4'], PALETTE['accent8']]\n    parts = ax1.violinplot(\n        [df[df['gender']==g]['daily_active_minutes_instagram'].dropna().sample(min(10000, len(df)), random_state=42)\n         for g in gender_order[:3]],\n        positions=range(len(gender_order[:3])),\n        showmeans=True, showmedians=True\n    )\n    for i, pc in enumerate(parts['bodies']):\n        pc.set_facecolor(colors_g[i % len(colors_g)])\n        pc.set_alpha(0.6)\n    parts['cmeans'].set_color(PALETTE['accent3'])\n    parts['cmedians'].set_color('white')\n    ax1.set_xticks(range(len(gender_order[:3])))\n    ax1.set_xticklabels(gender_order[:3], fontsize=9)\n    ax1.set_title('Daily Minutes by Gender', fontsize=11)\n\n# 2. Income Level Ã— Engagement Score\nax2 = fig.add_subplot(gs[0, 1])\nif 'income_level' in df.columns and 'user_engagement_score' in df.columns:\n    inc_order = ['Low', 'Medium', 'High']\n    inc_avail = [x for x in inc_order if x in df['income_level'].values]\n    if not inc_avail:\n        inc_avail = df['income_level'].value_counts().index[:5].tolist()\n    means = [df[df['income_level']==i]['user_engagement_score'].mean() for i in inc_avail]\n    bars = ax2.barh(inc_avail, means, color=IG_GRADIENT[:len(inc_avail)],\n                     edgecolor=PALETTE['grid'], height=0.6)\n    for bar, val in zip(bars, means):\n        ax2.text(val + 0.3, bar.get_y() + bar.get_height()/2,\n                 f'{val:.1f}', va='center', fontsize=9, color=PALETTE['text'])\n    ax2.set_title('Engagement Score by Income', fontsize=11)\n\n# 3. Urban vs Rural usage\nax3 = fig.add_subplot(gs[0, 2])\nif 'urban_rural' in df.columns:\n    ur_groups = df.groupby('urban_rural')['daily_active_minutes_instagram'].mean().sort_values()\n    colors_ur = [PALETTE['accent6'], PALETTE['accent1'], PALETTE['accent3']]\n    ax3.barh(ur_groups.index, ur_groups.values,\n             color=colors_ur[:len(ur_groups)], edgecolor=PALETTE['grid'], height=0.5)\n    for i, (idx, val) in enumerate(ur_groups.items()):\n        ax3.text(val + 0.5, i, f'{val:.1f} min', va='center', fontsize=9, color=PALETTE['text'])\n    ax3.set_title('Avg Daily Minutes: Urban vs Rural', fontsize=11)\n\n# 4. Top 10 Countries by Users\nax4 = fig.add_subplot(gs[1, 0])\nif 'country' in df.columns:\n    top_countries = df['country'].value_counts().head(10)\n    cmap_c = LinearSegmentedColormap.from_list('ig2', [PALETTE['accent1'], PALETTE['accent3']])\n    colors_c = [cmap_c(i/9) for i in range(10)]\n    ax4.barh(top_countries.index[::-1], top_countries.values[::-1],\n             color=colors_c, edgecolor=PALETTE['grid'], height=0.7)\n    ax4.set_title('Top 10 Countries by User Count', fontsize=11)\n    ax4.xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, _: f'{x/1000:.0f}K'))\n\n# 5. Education Ã— Posts per Week\nax5 = fig.add_subplot(gs[1, 1])\nif 'education_level' in df.columns and 'posts_created_per_week' in df.columns:\n    edu_posts = df.groupby('education_level')['posts_created_per_week'].mean().sort_values()\n    ax5.barh(edu_posts.index, edu_posts.values,\n             color=[IG_GRADIENT[i % len(IG_GRADIENT)] for i in range(len(edu_posts))],\n             edgecolor=PALETTE['grid'], height=0.6)\n    ax5.set_title('Posts/Week by Education', fontsize=11)\n\n# 6. Employment Ã— Sessions\nax6 = fig.add_subplot(gs[1, 2])\nif 'employment_status' in df.columns and 'sessions_per_day' in df.columns:\n    emp_sess = df.groupby('employment_status')['sessions_per_day'].mean().sort_values()\n    ax6.barh(emp_sess.index, emp_sess.values,\n             color=[NEON_SEQ[i % len(NEON_SEQ)] for i in range(len(emp_sess))],\n             edgecolor=PALETTE['grid'], height=0.6)\n    ax6.set_title('Sessions/Day by Employment', fontsize=11)\n\nfig.suptitle('Demographic Segmentation Ã— Instagram Behavior',\n             fontsize=18, fontweight='bold', color=PALETTE['accent3'], y=1.01)\nadd_watermark(fig)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T19:28:30.843642Z","iopub.execute_input":"2026-02-02T19:28:30.843983Z","iopub.status.idle":"2026-02-02T19:28:37.756686Z","shell.execute_reply.started":"2026-02-02T19:28:30.843946Z","shell.execute_reply":"2026-02-02T19:28:37.755299Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ğŸ”— Section 4 â€” Correlation Engine\n> Hierarchically clustered correlation matrix reveals feature families and hidden associations.\n","metadata":{}},{"cell_type":"code","source":"# â”€â”€ Hierarchically Clustered Correlation Matrix â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nnum_df = df[num_cols].sample(min(100000, len(df)), random_state=42)\ncorr = num_df.corr()\n\n# Hierarchical clustering to reorder\ndist = pdist(corr.values, metric='euclidean')\nlink = linkage(dist, method='ward')\norder = dendrogram(link, no_plot=True)['leaves']\ncorr_ordered = corr.iloc[order, order]\n\n# Custom diverging colormap\ncmap_corr = LinearSegmentedColormap.from_list(\n    'ig_div', [PALETTE['accent4'], PALETTE['bg'], PALETTE['accent2']]\n)\n\nfig, ax = plt.subplots(figsize=(18, 15))\nmask = np.triu(np.ones_like(corr_ordered, dtype=bool), k=1)\nim = ax.imshow(corr_ordered.where(~mask).values, cmap=cmap_corr,\n               vmin=-1, vmax=1, aspect='auto')\n\nax.set_xticks(range(len(corr_ordered)))\nax.set_xticklabels(corr_ordered.columns, rotation=90, fontsize=7)\nax.set_yticks(range(len(corr_ordered)))\nax.set_yticklabels(corr_ordered.index, fontsize=7)\n\n# Annotate strong correlations only\nfor i in range(len(corr_ordered)):\n    for j in range(i):\n        val = corr_ordered.iloc[i, j]\n        if abs(val) > 0.3:\n            ax.text(j, i, f'{val:.2f}', ha='center', va='center',\n                    fontsize=5.5, fontweight='bold',\n                    color='white' if abs(val) > 0.5 else PALETTE['muted'])\n\ncbar = fig.colorbar(im, ax=ax, shrink=0.6, pad=0.02)\ncbar.set_label('Pearson r', fontsize=10)\nax.set_title('Hierarchically Clustered Correlation Matrix â€” Strong Pairs Annotated (|r|>0.3)',\n             pad=20, fontsize=14)\nadd_watermark(fig)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T19:28:37.758476Z","iopub.execute_input":"2026-02-02T19:28:37.7589Z","iopub.status.idle":"2026-02-02T19:28:39.930561Z","shell.execute_reply.started":"2026-02-02T19:28:37.758859Z","shell.execute_reply":"2026-02-02T19:28:39.929662Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# â”€â”€ Top Correlation Pairs (bar chart) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\npairs = []\nfor i in range(len(corr.columns)):\n    for j in range(i+1, len(corr.columns)):\n        pairs.append((corr.columns[i], corr.columns[j], corr.iloc[i, j]))\n\npair_df = pd.DataFrame(pairs, columns=['Feat_A', 'Feat_B', 'r'])\npair_df['abs_r'] = pair_df['r'].abs()\n\n# Exclude trivially obvious pairs (same-concept duplicates)\npair_df = pair_df[pair_df['abs_r'] < 0.99].sort_values('abs_r', ascending=False)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))\n\n# Top positive\ntop_pos = pair_df[pair_df['r'] > 0].head(15)\nlabels_pos = [f\"{a}\\nÃ— {b}\" for a, b in zip(top_pos['Feat_A'], top_pos['Feat_B'])]\nax1.barh(range(len(top_pos)), top_pos['r'].values,\n         color=PALETTE['accent6'], edgecolor=PALETTE['grid'], alpha=0.85)\nax1.set_yticks(range(len(top_pos)))\nax1.set_yticklabels(labels_pos, fontsize=7)\nax1.set_xlabel('Pearson r')\nax1.set_title('ğŸŸ¢ Strongest Positive Correlations', fontsize=13, color=PALETTE['accent6'])\nax1.invert_yaxis()\n\n# Top negative\ntop_neg = pair_df[pair_df['r'] < 0].sort_values('r').head(15)\nlabels_neg = [f\"{a}\\nÃ— {b}\" for a, b in zip(top_neg['Feat_A'], top_neg['Feat_B'])]\nax2.barh(range(len(top_neg)), top_neg['r'].values,\n         color=PALETTE['accent7'], edgecolor=PALETTE['grid'], alpha=0.85)\nax2.set_yticks(range(len(top_neg)))\nax2.set_yticklabels(labels_neg, fontsize=7)\nax2.set_xlabel('Pearson r')\nax2.set_title('ğŸ”´ Strongest Negative Correlations', fontsize=13, color=PALETTE['accent7'])\nax2.invert_yaxis()\n\nfig.suptitle('Feature Pair Correlation Ranking', fontsize=16, fontweight='bold',\n             color=PALETTE['accent3'], y=1.02)\nadd_watermark(fig)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T19:28:39.93182Z","iopub.execute_input":"2026-02-02T19:28:39.932135Z","iopub.status.idle":"2026-02-02T19:28:40.516626Z","shell.execute_reply.started":"2026-02-02T19:28:39.932107Z","shell.execute_reply":"2026-02-02T19:28:40.515838Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ğŸ§  Section 5 â€” The Stressâ€“Screen Time Nexus\n> Exploring the dataset's built-in correlations: stress, happiness, sleep, and their relationship with Instagram consumption patterns.\n","metadata":{}},{"cell_type":"code","source":"# â”€â”€ Stress vs Daily Minutes (Hex-bin density) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nfig, axes = plt.subplots(1, 3, figsize=(20, 6))\n\ncombos = [\n    ('perceived_stress_score', 'daily_active_minutes_instagram', 'Stress â†’ Screen Time'),\n    ('self_reported_happiness', 'time_on_reels_per_day', 'Happiness â†’ Reels Time'),\n    ('sleep_hours_per_night', 'sessions_per_day', 'Sleep â†’ Sessions/Day'),\n]\n\nfor ax, (xc, yc, title) in zip(axes, combos):\n    if xc in df.columns and yc in df.columns:\n        sample = df[[xc, yc]].dropna().sample(min(80000, len(df)), random_state=42)\n        hb = ax.hexbin(sample[xc], sample[yc], gridsize=40,\n                        cmap=LinearSegmentedColormap.from_list('', [PALETTE['bg'], PALETTE['accent1'], PALETTE['accent3']]),\n                        mincnt=1, edgecolors='none')\n        fig.colorbar(hb, ax=ax, shrink=0.7, label='count')\n\n        # Trend line\n        z = np.polyfit(sample[xc], sample[yc], 1)\n        p = np.poly1d(z)\n        x_line = np.linspace(sample[xc].min(), sample[xc].max(), 100)\n        ax.plot(x_line, p(x_line), color=PALETTE['accent2'], lw=2.5, ls='--',\n                path_effects=[pe.withStroke(linewidth=4, foreground=PALETTE['bg'])])\n\n        r, pval = stats.pearsonr(sample[xc], sample[yc])\n        ax.text(0.05, 0.95, f'r = {r:.3f}  p = {pval:.1e}',\n                transform=ax.transAxes, fontsize=9, va='top',\n                color=PALETTE['accent4'], family='monospace',\n                bbox=dict(boxstyle='round,pad=0.3', facecolor=PALETTE['bg'], alpha=0.8))\n\n        ax.set_xlabel(xc.replace('_', ' ').title(), fontsize=9)\n        ax.set_ylabel(yc.replace('_', ' ').title(), fontsize=9)\n        ax.set_title(title, fontsize=12, color=PALETTE['accent3'])\n\nfig.suptitle('Wellbeing â†” Instagram Usage: Hexbin Density Maps',\n             fontsize=16, fontweight='bold', color=PALETTE['accent3'], y=1.04)\nadd_watermark(fig)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T19:28:40.517716Z","iopub.execute_input":"2026-02-02T19:28:40.518027Z","iopub.status.idle":"2026-02-02T19:28:41.805073Z","shell.execute_reply.started":"2026-02-02T19:28:40.517996Z","shell.execute_reply":"2026-02-02T19:28:41.804178Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# â”€â”€ Happiness Decile Behavioral Profile â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nif 'self_reported_happiness' in df.columns:\n    df['happiness_decile'] = pd.qcut(df['self_reported_happiness'], 10, labels=False, duplicates='drop')\n\n    behavior_cols = ['daily_active_minutes_instagram', 'reels_watched_per_day',\n                     'stories_viewed_per_day', 'likes_given_per_day',\n                     'time_on_feed_per_day', 'time_on_reels_per_day']\n    avail_cols = [c for c in behavior_cols if c in df.columns]\n\n    decile_means = df.groupby('happiness_decile')[avail_cols].mean()\n\n    # Normalize for radar-style heatmap\n    normed_dec = (decile_means - decile_means.min()) / (decile_means.max() - decile_means.min() + 1e-9)\n\n    fig, ax = plt.subplots(figsize=(14, 6))\n    cmap_h = LinearSegmentedColormap.from_list('', [PALETTE['accent4'], PALETTE['bg'], PALETTE['accent2']])\n    im = ax.imshow(normed_dec.T.values, cmap=cmap_h, aspect='auto')\n\n    ax.set_xticks(range(len(decile_means)))\n    ax.set_xticklabels([f'D{i+1}' for i in range(len(decile_means))], fontsize=10)\n    ax.set_xlabel('Happiness Decile (D1=Least Happy â†’ D10=Most Happy)', fontsize=10)\n    ax.set_yticks(range(len(avail_cols)))\n    ax.set_yticklabels([c.replace('_', ' ').title() for c in avail_cols], fontsize=9)\n\n    for i in range(normed_dec.shape[1]):\n        for j in range(normed_dec.shape[0]):\n            val = decile_means.iloc[j, i]\n            ax.text(j, i, f'{val:.1f}', ha='center', va='center', fontsize=7,\n                    color='white' if normed_dec.T.values[i, j] > 0.5 else PALETTE['muted'])\n\n    fig.colorbar(im, ax=ax, shrink=0.7, label='Normalized Intensity')\n    ax.set_title('How Instagram Usage Shifts Across Happiness Deciles',\n                 pad=15, fontsize=14, color=PALETTE['accent3'])\n    add_watermark(fig)\n    plt.tight_layout()\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T19:28:41.806165Z","iopub.execute_input":"2026-02-02T19:28:41.806498Z","iopub.status.idle":"2026-02-02T19:28:42.651775Z","shell.execute_reply.started":"2026-02-02T19:28:41.806471Z","shell.execute_reply":"2026-02-02T19:28:42.650593Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ğŸ“ˆ Section 6 â€” The Ageâ€“Behavior Gradient\n> How does Instagram behavior evolve across the age spectrum? Smoothed trend curves reveal the generational divide.\n","metadata":{}},{"cell_type":"code","source":"# â”€â”€ Smoothed Age Trends â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ntrend_cols = ['daily_active_minutes_instagram', 'reels_watched_per_day',\n              'posts_created_per_week', 'followers_count', 'sessions_per_day',\n              'time_on_reels_per_day']\navail_trend = [c for c in trend_cols if c in df.columns]\n\nfig, axes = plt.subplots(2, 3, figsize=(18, 10))\naxes = axes.flatten()\n\nfor i, col in enumerate(avail_trend):\n    ax = axes[i]\n    age_means = df.groupby('age')[col].mean()\n\n    # Rolling smooth\n    smoothed = age_means.rolling(window=3, center=True).mean()\n\n    ax.fill_between(smoothed.index, smoothed.values, alpha=0.3, color=IG_GRADIENT[i])\n    ax.plot(smoothed.index, smoothed.values, color=IG_GRADIENT[i], lw=3,\n            path_effects=[pe.withStroke(linewidth=5, foreground=PALETTE['bg'])])\n\n    # Peak annotation\n    peak_age = smoothed.idxmax()\n    peak_val = smoothed.max()\n    ax.annotate(f'Peak: age {peak_age}',\n                xy=(peak_age, peak_val),\n                xytext=(peak_age + 8, peak_val),\n                fontsize=8, color=PALETTE['accent4'],\n                arrowprops=dict(arrowstyle='->', color=PALETTE['accent4'], lw=1.5))\n\n    ax.set_title(col.replace('_', ' ').title(), fontsize=11, color=IG_GRADIENT[i])\n    ax.set_xlabel('Age')\n    ax.grid(True, alpha=0.15)\n\n# Hide extra axes\nfor j in range(len(avail_trend), len(axes)):\n    axes[j].set_visible(False)\n\nfig.suptitle('Instagram Metrics vs Age â€” Smoothed Trend Curves',\n             fontsize=16, fontweight='bold', color=PALETTE['accent3'], y=1.02)\nadd_watermark(fig)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T19:28:42.653123Z","iopub.execute_input":"2026-02-02T19:28:42.653412Z","iopub.status.idle":"2026-02-02T19:28:44.280873Z","shell.execute_reply.started":"2026-02-02T19:28:42.653388Z","shell.execute_reply":"2026-02-02T19:28:44.279762Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ğŸ§¬ Section 7 â€” User Persona Discovery via Clustering\n> Using KMeans + PCA/UMAP to discover latent user archetypes within the behavioral space.\n","metadata":{}},{"cell_type":"code","source":"# â”€â”€ Feature Engineering for Clustering â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ncluster_features = [\n    'daily_active_minutes_instagram', 'sessions_per_day',\n    'posts_created_per_week', 'reels_watched_per_day',\n    'stories_viewed_per_day', 'likes_given_per_day',\n    'comments_written_per_day', 'followers_count',\n    'time_on_feed_per_day', 'time_on_reels_per_day',\n    'perceived_stress_score', 'self_reported_happiness',\n    'sleep_hours_per_night', 'age'\n]\navail_cf = [c for c in cluster_features if c in df.columns]\n\n# Sample for speed\nsample_size = 30000\nsample_df = df[avail_cf].dropna().sample(sample_size, random_state=42)\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(sample_df)\n\n# Elbow method\ninertias = []\nK_range = range(2, 9)\nfor k in K_range:\n    km = KMeans(n_clusters=k, n_init=10, random_state=42, max_iter=100)\n    km.fit(X_scaled)\n    inertias.append(km.inertia_)\n\nfig, ax = plt.subplots(figsize=(10, 5))\nax.plot(K_range, inertias, 'o-', color=PALETTE['accent4'], lw=2.5, markersize=8)\nax.fill_between(K_range, inertias, alpha=0.15, color=PALETTE['accent4'])\nax.set_xlabel('Number of Clusters (K)')\nax.set_ylabel('Inertia')\nax.set_title('Elbow Method for Optimal K', fontsize=14, color=PALETTE['accent3'])\nax.grid(True, alpha=0.15)\nadd_watermark(fig)\nplt.tight_layout()\nplt.show()\n\n# Fit with chosen K\nK_CHOSEN = 5\nkm_final = KMeans(n_clusters=K_CHOSEN, n_init=20, random_state=42)\nlabels = km_final.fit_predict(X_scaled)\nsample_df = sample_df.copy()\nsample_df['cluster'] = labels\nprint(f\"âœ… KMeans fitted with K={K_CHOSEN} â€” cluster sizes:\")\nprint(sample_df['cluster'].value_counts().sort_index())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T19:28:44.285001Z","iopub.execute_input":"2026-02-02T19:28:44.285345Z","iopub.status.idle":"2026-02-02T19:28:55.44156Z","shell.execute_reply.started":"2026-02-02T19:28:44.285317Z","shell.execute_reply":"2026-02-02T19:28:55.440624Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# â”€â”€ PCA 2D Projection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\npca = PCA(n_components=2, random_state=42)\nX_pca = pca.fit_transform(X_scaled)\n\nfig, ax = plt.subplots(figsize=(14, 10))\nscatter_colors = [PALETTE['accent4'], PALETTE['accent7'], PALETTE['accent6'],\n                  PALETTE['accent3'], PALETTE['accent1'], PALETTE['accent5']]\n\nfor c in range(K_CHOSEN):\n    mask = labels == c\n    ax.scatter(X_pca[mask, 0], X_pca[mask, 1],\n               c=scatter_colors[c], s=4, alpha=0.35, label=f'Cluster {c}')\n\n    # Centroid label\n    cx, cy = X_pca[mask, 0].mean(), X_pca[mask, 1].mean()\n    ax.scatter(cx, cy, c=scatter_colors[c], s=200, marker='D',\n               edgecolors='white', linewidths=2, zorder=5)\n    ax.annotate(f'C{c}', (cx, cy), fontsize=12, fontweight='bold',\n                color='white', ha='center', va='center', zorder=6)\n\nax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)')\nax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)')\nax.set_title('User Clusters â€” PCA Projection', fontsize=16, color=PALETTE['accent3'])\nax.legend(loc='upper right', framealpha=0.8)\nax.grid(True, alpha=0.1)\nadd_watermark(fig)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T19:28:55.4427Z","iopub.execute_input":"2026-02-02T19:28:55.443032Z","iopub.status.idle":"2026-02-02T19:28:56.025662Z","shell.execute_reply.started":"2026-02-02T19:28:55.443005Z","shell.execute_reply":"2026-02-02T19:28:56.024413Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# â”€â”€ Cluster Radar Profiles â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nradar_cols = [c for c in avail_cf if c != 'age'][:8]  # Select up to 8 for readability\n\ncluster_means = sample_df.groupby('cluster')[radar_cols].mean()\n# Normalize to 0-1 for radar\nradar_normed = (cluster_means - cluster_means.min()) / (cluster_means.max() - cluster_means.min() + 1e-9)\n\nangles = np.linspace(0, 2*np.pi, len(radar_cols), endpoint=False).tolist()\nangles += angles[:1]\n\nfig, axes = plt.subplots(1, K_CHOSEN, figsize=(4*K_CHOSEN, 5),\n                          subplot_kw=dict(polar=True))\n\npersona_names = ['ğŸŒ™ Night Scroller', 'ğŸ“¸ Content Creator',\n                 'ğŸ‘€ Passive Lurker', 'âš¡ Power User', 'ğŸ§˜ Balanced User']\n\nfor c in range(K_CHOSEN):\n    ax = axes[c] if K_CHOSEN > 1 else axes\n    values = radar_normed.iloc[c].values.tolist()\n    values += values[:1]\n\n    ax.fill(angles, values, color=scatter_colors[c], alpha=0.25)\n    ax.plot(angles, values, color=scatter_colors[c], lw=2.5)\n    ax.scatter(angles[:-1], values[:-1], color=scatter_colors[c], s=30, zorder=5)\n\n    ax.set_xticks(angles[:-1])\n    ax.set_xticklabels([c.replace('_', '\\n').replace(' ', '\\n')[:20]\n                         for c in radar_cols], fontsize=5.5)\n    ax.set_ylim(0, 1.1)\n    ax.set_yticks([0.25, 0.5, 0.75, 1.0])\n    ax.set_yticklabels(['', '', '', ''], fontsize=6)\n    ax.grid(color=PALETTE['grid'], alpha=0.3)\n    ax.set_facecolor(PALETTE['card'])\n    name = persona_names[c] if c < len(persona_names) else f'Cluster {c}'\n    ax.set_title(name, fontsize=10, color=scatter_colors[c], pad=15, fontweight='bold')\n\nfig.suptitle('Cluster Behavioral Fingerprints â€” Radar Profiles',\n             fontsize=16, fontweight='bold', color=PALETTE['accent3'], y=1.06)\nadd_watermark(fig)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T19:28:56.026987Z","iopub.execute_input":"2026-02-02T19:28:56.027572Z","iopub.status.idle":"2026-02-02T19:28:56.969254Z","shell.execute_reply.started":"2026-02-02T19:28:56.027536Z","shell.execute_reply":"2026-02-02T19:28:56.968328Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# â”€â”€ Cluster Summary Table â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nsummary = sample_df.groupby('cluster')[avail_cf].agg(['mean', 'median']).round(2)\nsummary.columns = [f'{col}_{stat}' for col, stat in summary.columns]\nprint(\"\\nğŸ“‹ Cluster Summary Statistics:\")\ndisplay(sample_df.groupby('cluster')[avail_cf].mean().round(2).T)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T19:28:56.970677Z","iopub.execute_input":"2026-02-02T19:28:56.971063Z","iopub.status.idle":"2026-02-02T19:28:57.026598Z","shell.execute_reply.started":"2026-02-02T19:28:56.971026Z","shell.execute_reply":"2026-02-02T19:28:57.025709Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ğŸ¨ Section 8 â€” Interactive Exploration (Plotly)\n> Hover, zoom, and filter with interactive charts powered by Plotly.\n","metadata":{}},{"cell_type":"code","source":"# â”€â”€ Interactive: Age vs Screen Time colored by Happiness â”€â”€â”€â”€â”€â”€\nplot_sample = df.dropna(subset=['age', 'daily_active_minutes_instagram',\n                                  'self_reported_happiness']).sample(\n    min(15000, len(df)), random_state=42\n)\n\nfig = px.scatter(\n    plot_sample,\n    x='age',\n    y='daily_active_minutes_instagram',\n    color='self_reported_happiness',\n    color_continuous_scale=['#833ab4', '#fd1d1d', '#fcb045'],\n    opacity=0.4,\n    title='<b>Age vs Screen Time</b> â€” colored by Self-Reported Happiness',\n    labels={\n        'age': 'Age',\n        'daily_active_minutes_instagram': 'Daily Active Minutes',\n        'self_reported_happiness': 'Happiness'\n    },\n    template='plotly_dark',\n    height=550,\n)\nfig.update_layout(\n    font_family='Courier New',\n    title_font_size=18,\n    plot_bgcolor='#0d1117',\n    paper_bgcolor='#0d1117',\n)\nfig.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T19:28:57.027978Z","iopub.execute_input":"2026-02-02T19:28:57.028288Z","iopub.status.idle":"2026-02-02T19:29:04.913037Z","shell.execute_reply.started":"2026-02-02T19:28:57.028263Z","shell.execute_reply":"2026-02-02T19:29:04.91223Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# â”€â”€ Interactive: Sunburst of User Segments â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ncat_cols_check = ['gender', 'income_level', 'urban_rural']\ncat_cols_avail = [c for c in cat_cols_check if c in df.columns]\n\nif len(cat_cols_avail) >= 2:\n    sunburst_df = df.groupby(cat_cols_avail).agg(\n        avg_minutes=('daily_active_minutes_instagram', 'mean'),\n        count=('daily_active_minutes_instagram', 'size')\n    ).reset_index()\n\n    fig = px.sunburst(\n        sunburst_df,\n        path=cat_cols_avail,\n        values='count',\n        color='avg_minutes',\n        color_continuous_scale=['#833ab4', '#fd1d1d', '#fcb045'],\n        title='<b>User Segmentation Sunburst</b> â€” Size=Count, Color=Avg Minutes',\n        template='plotly_dark',\n        height=600,\n    )\n    fig.update_layout(\n        font_family='Courier New',\n        paper_bgcolor='#0d1117',\n    )\n    fig.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T19:29:04.914259Z","iopub.execute_input":"2026-02-02T19:29:04.915174Z","iopub.status.idle":"2026-02-02T19:29:05.84087Z","shell.execute_reply.started":"2026-02-02T19:29:04.915137Z","shell.execute_reply":"2026-02-02T19:29:05.839684Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":" ## ğŸ’ª Section 9 â€” Health Ã— Digital Behavior Matrix\n> Do healthier lifestyles correlate with different Instagram patterns? Let's visualize the intersection.\n","metadata":{}},{"cell_type":"code","source":"# â”€â”€ Multi-scatter: Health metrics vs Instagram time â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nhealth_cols = ['exercise_hours_per_week', 'sleep_hours_per_night',\n               'body_mass_index', 'daily_steps_count']\nig_target = 'daily_active_minutes_instagram'\n\navail_health = [c for c in health_cols if c in df.columns and ig_target in df.columns]\n\nif avail_health:\n    n = len(avail_health)\n    fig, axes = plt.subplots(1, n, figsize=(5*n, 5))\n    if n == 1:\n        axes = [axes]\n\n    for i, hcol in enumerate(avail_health):\n        ax = axes[i]\n        s = df[[hcol, ig_target]].dropna().sample(min(20000, len(df)), random_state=42)\n\n        ax.hexbin(s[hcol], s[ig_target], gridsize=30, mincnt=1,\n                  cmap=LinearSegmentedColormap.from_list('', [PALETTE['bg'], NEON_SEQ[i], 'white']),\n                  edgecolors='none')\n\n        # Binned means overlay\n        s['bin'] = pd.qcut(s[hcol], 20, labels=False, duplicates='drop')\n        bin_means = s.groupby('bin')[[hcol, ig_target]].mean()\n        ax.plot(bin_means[hcol], bin_means[ig_target], 'o-',\n                color='white', lw=2, markersize=4, alpha=0.9,\n                path_effects=[pe.withStroke(linewidth=3, foreground=PALETTE['bg'])])\n\n        r, p = stats.pearsonr(s[hcol], s[ig_target])\n        ax.text(0.05, 0.95, f'r={r:.3f}', transform=ax.transAxes,\n                fontsize=9, color=PALETTE['accent4'], va='top', family='monospace',\n                bbox=dict(facecolor=PALETTE['bg'], alpha=0.7, boxstyle='round'))\n\n        ax.set_xlabel(hcol.replace('_', ' ').title(), fontsize=9)\n        ax.set_ylabel('Daily Active Min' if i == 0 else '', fontsize=9)\n        ax.set_title(hcol.replace('_', ' ').title(), fontsize=10,\n                     color=NEON_SEQ[i])\n\n    fig.suptitle('Health & Lifestyle â†’ Instagram Screen Time',\n                 fontsize=15, fontweight='bold', color=PALETTE['accent3'], y=1.04)\n    add_watermark(fig)\n    plt.tight_layout()\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T19:29:05.842168Z","iopub.execute_input":"2026-02-02T19:29:05.842494Z","iopub.status.idle":"2026-02-02T19:29:07.293968Z","shell.execute_reply.started":"2026-02-02T19:29:05.842465Z","shell.execute_reply":"2026-02-02T19:29:07.292846Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ğŸ¯ Section 10 â€” Feature Importance for Engagement Score\n> Which features most strongly predict user engagement? Using mutual information as a model-free importance metric.\n","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import mutual_info_regression\n\ntarget = 'user_engagement_score'\nif target in df.columns:\n    feat_cols = [c for c in num_cols if c != target and c in df.columns]\n    mi_sample = df[feat_cols + [target]].dropna().sample(min(50000, len(df)), random_state=42)\n\n    X_mi = mi_sample[feat_cols]\n    y_mi = mi_sample[target]\n\n    mi_scores = mutual_info_regression(X_mi, y_mi, random_state=42, n_neighbors=5)\n    mi_df = pd.DataFrame({'feature': feat_cols, 'MI': mi_scores}).sort_values('MI', ascending=True)\n\n    fig, ax = plt.subplots(figsize=(12, max(8, len(mi_df)*0.3)))\n\n    colors = [IG_GRADIENT[int(i / len(mi_df) * (len(IG_GRADIENT)-1))]\n              for i in range(len(mi_df))]\n\n    ax.barh(mi_df['feature'], mi_df['MI'], color=colors,\n            edgecolor=PALETTE['grid'], height=0.7)\n\n    # Top 5 highlight\n    for idx, row in mi_df.tail(5).iterrows():\n        ax.text(row['MI'] + mi_df['MI'].max()*0.01,\n                mi_df.index.tolist().index(idx),\n                f\"  {row['MI']:.4f}\", va='center', fontsize=8,\n                color=PALETTE['accent3'], fontweight='bold')\n\n    ax.set_xlabel('Mutual Information Score')\n    ax.set_title('Feature Importance for Engagement Score â€” Mutual Information',\n                 fontsize=14, color=PALETTE['accent3'], pad=15)\n    ax.grid(True, axis='x', alpha=0.15)\n    add_watermark(fig)\n    plt.tight_layout()\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T19:29:07.295095Z","iopub.execute_input":"2026-02-02T19:29:07.295378Z","iopub.status.idle":"2026-02-02T19:29:25.330437Z","shell.execute_reply.started":"2026-02-02T19:29:07.295353Z","shell.execute_reply":"2026-02-02T19:29:25.329436Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ğŸ Key Takeaways\n\n<div style=\"background: linear-gradient(135deg, #833ab4, #fd1d1d, #fcb045); padding: 2px; border-radius: 12px; margin: 20px 0;\">\n<div style=\"background: #0d1117; padding: 24px; border-radius: 11px; color: #c9d1d9; line-height: 1.8;\">\n\n**1. The Stressâ€“Screen Spiral** â€” Higher perceived stress correlates with increased daily active minutes and heavier reels consumption, suggesting a \"doom-scrolling\" feedback loop.\n\n**2. The Happiness Gradient** â€” Less happy users spend disproportionately more time on feed and reels, while happier users show more balanced, intentional usage patterns.\n\n**3. Generational Divide** â€” Users under 28 (Gen Z) dominate reels consumption, post creation, and follower accumulation. Usage drops sharply after age 45.\n\n**4. Health Buffer Effect** â€” Better sleep and more exercise hours show modest but consistent inverse relationships with compulsive usage metrics.\n\n**5. Distinct User Personas** â€” KMeans clustering reveals at least 5 archetypes: Night Scrollers, Content Creators, Passive Lurkers, Power Users, and Balanced Users â€” each with distinct behavioral fingerprints.\n\n**6. Engagement Drivers** â€” Mutual information analysis reveals that session frequency, reels consumption, and content creation are the strongest predictors of engagement score â€” more so than demographic features.\n\n</div>\n</div>\n\n---\n*Notebook: Instagram Behavioral Genome EDA Â· 1M Synthetic Users Â· Built with matplotlib, seaborn, plotly, scikit-learn*\n","metadata":{}}]}